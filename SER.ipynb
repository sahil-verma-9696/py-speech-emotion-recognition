{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil-verma-9696/py-speech-emotion-recognition/blob/main/SER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "iwZ6haCD_XLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuC8HKUAaALy",
        "outputId": "2424c2a3-4fe4-477f-bc4b-5840c217a72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV created: sentence_emotion_mapping.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sentences = [\n",
        "    \"सूरज एक अच्छा विद्यार्थी है।\",\n",
        "    \"गणित का प्रश्न पत्र कठिन था।\",\n",
        "    \"मुझे अच्छे अंक लाने हैं।\",\n",
        "    \"रीना पढ़ाई में सबकी मदद करती है।\",\n",
        "    \"विद्यार्थी आंदोलन कर रहे थे।\",\n",
        "    \"मैंने यह पाठ पूरा नहीं पढ़ा है।\",\n",
        "    \"अच्छा विद्यार्थी अहंकार से दूर रहता है।\",\n",
        "    \"विद्यार्थियों को ईमानदार होना चाहिए।\",\n",
        "    \"आप सभी मन लगाकर पढ़िए।\",\n",
        "    \"विद्यार्थी परिणाम का इंतजार कर रहे थे।\"\n",
        "]\n",
        "\n",
        "emotions = [\n",
        "    \"Anger\",\n",
        "    \"disgust\",\n",
        "    \"fear\",\n",
        "    \"happy\",\n",
        "    \"neutral\",\n",
        "    \"sad\",\n",
        "    \"sarcastic\",\n",
        "    \"surprise\"\n",
        "]\n",
        "\n",
        "# Generate all combinations\n",
        "data = [{\"text\": sentence, \"emotion\": emotion} for sentence in sentences for emotion in emotions]\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"sentence_emotion_mapping.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"✅ CSV created: sentence_emotion_mapping.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"sentence_emotion_mapping.csv\")\n",
        "# print(df)/content/drive/MyDrive/dataset/my Dataset"
      ],
      "metadata": {
        "id": "iW2w60RzeeKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# Replace with your dataset root\n",
        "base_dir = '/content/drive/MyDrive/dataset/my Dataset/1'\n",
        "\n",
        "# Output CSV file path\n",
        "output_csv = 'audio_mapping.csv'\n",
        "sentences = [\n",
        "    \"सूरज एक अच्छा विद्यार्थी है।\",\n",
        "    \"गणित का प्रश्न पत्र कठिन था।\",\n",
        "    \"मुझे अच्छे अंक लाने हैं।\",\n",
        "    \"रीना पढ़ाई में सबकी मदद करती है।\",\n",
        "    \"विद्यार्थी आंदोलन कर रहे थे।\",\n",
        "    \"मैंने यह पाठ पूरा नहीं पढ़ा है।\",\n",
        "    \"अच्छा विद्यार्थी अहंकार से दूर रहता है।\",\n",
        "    \"विद्यार्थियों को ईमानदार होना चाहिए।\",\n",
        "    \"आप सभी मन लगाकर पढ़िए।\",\n",
        "    \"विद्यार्थी परिणाम का इंतजार कर रहे थे।\"\n",
        "]\n",
        "\n",
        "# Dummy function for transcription (replace this with Whisper or any STT engine)\n",
        "def transcribe_audio(filename):\n",
        "    core = filename.rsplit('.', 1)[0]   # '1.1.anger-01'\n",
        "    last_part = core.rsplit('-', 1)[-1] # '01'\n",
        "\n",
        "    print(sentences[int(last_part)-1])\n",
        "\n",
        "    return sentences[int(last_part)-1]\n",
        "\n",
        "# Collect data\n",
        "data = []\n",
        "\n",
        "for root, _, files in os.walk(base_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            parts = file_path.split(os.sep)\n",
        "\n",
        "            try:\n",
        "                # Assuming emotion is always at index -2: session1/anger/filename\n",
        "                emotion_name = parts[-2]\n",
        "                spoken_text = transcribe_audio(file_path)\n",
        "\n",
        "                data.append([file_path, emotion_name, spoken_text])\n",
        "            except IndexError:\n",
        "                print(f\"Skipping {file_path} due to unexpected format\")\n",
        "\n",
        "# Write to CSV\n",
        "with open(output_csv, 'w', newline='',encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['file_path', 'emotion_name', 'spoken_text'])\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(f\"CSV saved to {output_csv}\")\n"
      ],
      "metadata": {
        "id": "HqYUYiczJ7p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 * 5 * 8 * 10 = 3200\n",
        "person.session.emotion-sentence\n"
      ],
      "metadata": {
        "id": "GZeFNnSevZLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "from google.colab import auth\n",
        "import google.auth\n",
        "\n",
        "# Authenticate and build the Drive service\n",
        "auth.authenticate_user()\n",
        "creds, _ = google.auth.default()\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "def get_folder_id_by_path(path):\n",
        "    path_parts = path.strip('/').split('/')\n",
        "    folder_id = 'root'\n",
        "\n",
        "    for part in path_parts:\n",
        "        query = f\"'{folder_id}' in parents and name = '{part}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
        "        result = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "        files = result.get('files', [])\n",
        "        if not files:\n",
        "            raise Exception(f\"Folder '{part}' not found under parent ID {folder_id}\")\n",
        "        folder_id = files[0]['id']\n",
        "\n",
        "    return folder_id\n",
        "\n",
        "# Get source folder ID\n",
        "source_path = 'dataset'\n",
        "source_id = get_folder_id_by_path(source_path)\n",
        "print(f\"Source Folder ID: {source_id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1n1zzhLxHhM",
        "outputId": "727efb22-c85d-4465-8de5-c2e6485fc5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Folder ID: 1Od_8WezSCPXF18LWKwTe7GDyIQsGwQAd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import google.auth\n",
        "\n",
        "# Authenticate and build Drive API client\n",
        "auth.authenticate_user()\n",
        "creds, _ = google.auth.default()\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "SOURCE_FOLDER_ID = '1Ac57ZNbwjy1fQ1jZ-43x02tXAYtc1ppf'  # Your nested folder ID\n",
        "DEST_FOLDER_ID = '1Od_8WezSCPXF18LWKwTe7GDyIQsGwQAd'  # Replace after getting it\n",
        "\n",
        "def list_all_files_recursive(folder_id):\n",
        "    files = []\n",
        "    query = f\"'{folder_id}' in parents and trashed = false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name, mimeType)\").execute()\n",
        "\n",
        "    for file in results.get('files', []):\n",
        "        if file['mimeType'] == 'application/vnd.google-apps.folder':\n",
        "            files.extend(list_all_files_recursive(file['id']))\n",
        "        else:\n",
        "            files.append(file)\n",
        "    return files\n",
        "\n",
        "def move_file(file_id, new_parent_id):\n",
        "    file = drive_service.files().get(fileId=file_id, fields='parents').execute()\n",
        "    previous_parents = \",\".join(file.get('parents'))\n",
        "    drive_service.files().update(\n",
        "        fileId=file_id,\n",
        "        addParents=new_parent_id,\n",
        "        removeParents=previous_parents,\n",
        "        fields='id, parents'\n",
        "    ).execute()\n",
        "\n",
        "# Flattening begins\n",
        "files_to_move = list_all_files_recursive(SOURCE_FOLDER_ID)\n",
        "print(f\"Found {len(files_to_move)} files to move.\")\n",
        "\n",
        "for file in files_to_move:\n",
        "    print(f\"Moving: {file['name']}\")\n",
        "    move_file(file['id'], DEST_FOLDER_ID)\n",
        "\n",
        "print(\"✅ All files moved and folder flattened.\")"
      ],
      "metadata": {
        "id": "8FF1MXaw1WrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/gdrive/MyDrive/ser_ds/audios'\n",
        "import os"
      ],
      "metadata": {
        "id": "jLkz_fBtmrDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentences = [\n",
        "    \"सूरज एक अच्छा विद्यार्थी है।\",\n",
        "    \"गणित का प्रश्न पत्र कठिन था।\",\n",
        "    \"मुझे अच्छे अंक लाने हैं।\",\n",
        "    \"रीना पढ़ाई में सबकी मदद करती है।\",\n",
        "    \"विद्यार्थी आंदोलन कर रहे थे।\",\n",
        "    \"मैंने यह पाठ पूरा नहीं पढ़ा है।\",\n",
        "    \"अच्छा विद्यार्थी अहंकार से दूर रहता है।\",\n",
        "    \"विद्यार्थियों को ईमानदार होना चाहिए।\",\n",
        "    \"आप सभी मन लगाकर पढ़िए।\",\n",
        "    \"विद्यार्थी परिणाम का इंतजार कर रहे थे।\"\n",
        "]\n",
        "\n",
        "emotions = [\n",
        "    \"Anger\",\n",
        "    \"disgust\",\n",
        "    \"fear\",\n",
        "    \"happy\",\n",
        "    \"neutral\",\n",
        "    \"sad\",\n",
        "    \"sarcastic\",\n",
        "    \"surprise\"\n",
        "]"
      ],
      "metadata": {
        "id": "z6dVTYFlrr8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import traceback"
      ],
      "metadata": {
        "id": "PVQDlVKitX3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "cnt= 1\n",
        "for root, _, files in os.walk(path):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            parts = file_path.split(os.sep)\n",
        "            try:\n",
        "              arr.append({'id': cnt, 'file_path': file_path, 'emotion': parts[-1].split('.')[-2][:-2] , 'text': sentences[int(parts[-1].split('.')[-2][-2:]) - 1] })\n",
        "              cnt+=1\n",
        "            except Exception as e:\n",
        "              print(file_path)\n",
        "              print(parts)\n",
        "              print( parts[-1].split('.')[-2].split('-')[0] )\n",
        "              print( parts[-1].split('.')[-2].split('-')[1] )\n",
        "              print(sentences[int(parts[-1].split('.')[-2].split('-')[1]) - 1])\n",
        "\n",
        "              print(traceback.format_exc())\n",
        "              print(f\"Skipping {file_path} due to unexpected format\")\n",
        "\n",
        "df = pd.DataFrame(arr)\n",
        "df.to_csv(\"/gdrive/MyDrive/ser_ds/SER_ds_csv.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"✅ CSV created: sentence_emotion_mapping.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCBI7YvxmrGB",
        "outputId": "24ebd155-64e2-4944-b82c-302b48743d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV created: sentence_emotion_mapping.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# audio file link - https://drive.google.com/drive/folders/1Od_8WezSCPXF18LWKwTe7GDyIQsGwQAd?usp=drive_linkm\n",
        "# ds link - https://drive.google.com/file/d/1OCDGB2qjIVVQ-3DiSUZPiQmBMJDTW8r9/view?usp=drive_link"
      ],
      "metadata": {
        "id": "pwX3GKsivEdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRB7AXrRvEgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df\n"
      ],
      "metadata": {
        "id": "qW8UPboSmrIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Q79FQv-VvPQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0dFy10Um3xGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting the features from audio"
      ],
      "metadata": {
        "id": "k2qyKf13EVPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 1. Install Dependencies\n",
        "# --------------------------\n",
        "!pip install librosa soundfile praat-parselmouth numpy scipy\n",
        "\n",
        "# --------------------------\n",
        "# 2. Import Required Libraries\n",
        "# --------------------------\n",
        "import librosa\n",
        "import numpy as np\n",
        "import parselmouth\n",
        "import soundfile as sf"
      ],
      "metadata": {
        "id": "c-gXWBZVEa-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8db968d-61c6-4ea8-a99d-2289bd288ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Downloading praat_parselmouth-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Automatically get filename\n",
        "audio_path = '/content/drive/MyDrive/dataset/1.1.anger-01.wav'\n",
        "\n",
        "# --------------------------\n",
        "# 5. Feature Extraction Function\n",
        "# --------------------------\n",
        "def extract_all_features(audio_path):\n",
        "    import librosa\n",
        "    import numpy as np\n",
        "    import parselmouth\n",
        "\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "    # MFCC\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).mean(axis=1)\n",
        "\n",
        "    # Chroma\n",
        "    chroma = librosa.feature.chroma_stft(y=y, sr=sr).mean(axis=1)\n",
        "\n",
        "    # Spectral Contrast\n",
        "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr).mean(axis=1)\n",
        "\n",
        "    # Tonnetz\n",
        "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr).mean(axis=1)\n",
        "\n",
        "    # Zero Crossing Rate\n",
        "    zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
        "\n",
        "    # Spectral Features\n",
        "    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
        "    spec_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
        "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
        "\n",
        "    # Root Mean Square Energy\n",
        "    rmse = librosa.feature.rms(y=y).mean()\n",
        "\n",
        "    # Pitch\n",
        "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
        "    pitch_values = pitches[pitches > 0]\n",
        "    pitch_mean = pitch_values.mean() if len(pitch_values) > 0 else 0\n",
        "\n",
        "    # Parselmouth for jitter, shimmer, HNR\n",
        "    snd = parselmouth.Sound(audio_path)\n",
        "    point_process = parselmouth.praat.call(snd, \"To PointProcess (periodic, cc)\", 75, 500)\n",
        "\n",
        "    # Jitter\n",
        "    jitter_local = parselmouth.praat.call(point_process, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "\n",
        "    # Shimmer\n",
        "    shimmer_local = parselmouth.praat.call([snd, point_process], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "\n",
        "    # Harmonics-to-Noise Ratio (HNR)\n",
        "    harmonicity = parselmouth.praat.call(snd, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
        "    hnr = parselmouth.praat.call(harmonicity, \"Get mean\", 0, 0)\n",
        "\n",
        "    # Combine all features\n",
        "    feature_vector = np.hstack([\n",
        "        mfccs,\n",
        "        chroma,\n",
        "        spec_contrast,\n",
        "        tonnetz,\n",
        "        zcr,\n",
        "        spec_centroid,\n",
        "        spec_bandwidth,\n",
        "        spec_rolloff,\n",
        "        rmse,\n",
        "        pitch_mean,\n",
        "        jitter_local,\n",
        "        shimmer_local,\n",
        "        hnr\n",
        "    ])\n",
        "\n",
        "    return feature_vector\n",
        "\n",
        "# --------------------------\n",
        "# 6. Extract and Print Features\n",
        "# --------------------------\n",
        "features = extract_all_features(audio_path)\n",
        "print(\"Extracted feature vector (length={}):\".format(len(features)))\n",
        "print(features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkUhoWOXhAux",
        "outputId": "4cbe81bf-5c95-44d2-a28e-e6c6415ef80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted feature vector (length=47):\n",
            "[-3.98995758e+02  9.67277679e+01 -3.38579154e+00  1.80757847e+01\n",
            " -2.97621422e+01 -8.93530083e+00 -4.56137323e+00 -1.22554865e+01\n",
            " -1.89918671e+01 -1.13129320e+01 -1.63695412e+01 -1.77026291e+01\n",
            " -8.24666977e+00  5.50655305e-01  4.30559635e-01  3.31397891e-01\n",
            "  2.76145458e-01  3.28886867e-01  3.89419079e-01  3.93849581e-01\n",
            "  4.18670207e-01  3.49334031e-01  4.01092172e-01  4.44719464e-01\n",
            "  5.23074687e-01  2.30516856e+01  1.63047989e+01  1.79890790e+01\n",
            "  1.76174481e+01  1.70567081e+01  2.01933760e+01  1.89000991e+01\n",
            "  1.24771587e-02  2.47011746e-02  1.15165342e-02  3.50669621e-02\n",
            " -9.10471638e-03  7.29467026e-03  1.05894697e-01  1.62527663e+03\n",
            "  1.61038684e+03  3.31017287e+03  1.57346204e-02  9.48319153e+02\n",
            "  2.20069688e-02  1.01566960e-01  1.33835968e+01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "X_O4uwJoJF91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "foSxdvqTgq6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f79372-727c-4dd7-dca4-ba6493047646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Install dependencies\n",
        "!pip install librosa tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siY5ixMgJPvB",
        "outputId": "35365673-e4ee-4b2a-c727-a381b61daabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.2)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Import required libraries\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Attention\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import os"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nqn1gip5JW43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Feature extraction function (MFCCs)\n",
        "def extract_mfcc(file_path, max_len=300):\n",
        "    y, sr = librosa.load(file_path, sr=16000)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "    mfcc = mfcc.T\n",
        "    if len(mfcc) > max_len:\n",
        "        mfcc = mfcc[:max_len]\n",
        "    else:\n",
        "        mfcc = np.pad(mfcc, ((0, max_len - len(mfcc)), (0, 0)))\n",
        "    return mfcc\n"
      ],
      "metadata": {
        "id": "sKqvdAqMJnLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Load your sample\n",
        "file_path = \"/content/drive/MyDrive/dataset/1.1.anger-01.wav\"\n",
        "X_sample = extract_mfcc(file_path)\n",
        "X_sample = np.expand_dims(X_sample, axis=0)  # Shape: (1, time_steps, 40)\n",
        "\n",
        "\n",
        "\n",
        "# Simulate label for demonstration (anger → class 0)\n",
        "y_sample = tf.keras.utils.to_categorical([0], num_classes=4)  # Assume 4 emotions\n"
      ],
      "metadata": {
        "id": "CyOY2B8hJt56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "\n",
        "# Input\n",
        "input_layer = Input(shape=(X_sample.shape[1], 40))\n",
        "\n",
        "# CNN\n",
        "x = Conv1D(128, kernel_size=5, activation='relu')(input_layer)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "# BiLSTM\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "\n",
        "# Attention\n",
        "attention_out = Attention()([x, x])  # (batch_size, timesteps, features)\n",
        "\n",
        "# Replace reduce_mean with a proper Keras layer\n",
        "context_vector = GlobalAveragePooling1D()(attention_out)\n",
        "\n",
        "# Output\n",
        "output_layer = Dense(4, activation='softmax')(context_vector)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "xMcAeMBCJxWQ",
        "outputId": "c35e9ce7-2e1c-478c-b1f2-649d33921a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m296\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m25,728\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,728</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,060\u001b[0m (488.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,060</span> (488.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m125,060\u001b[0m (488.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,060</span> (488.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}